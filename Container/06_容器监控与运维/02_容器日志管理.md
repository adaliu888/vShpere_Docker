    # 容器日志管理深度解析

## 目录

- [容器日志管理深度解析](#容器日志管理深度解析)
  - [1. 容器日志概述](#1-容器日志概述)
    - [1.1 日志类型与特点](#11-日志类型与特点)
      - [日志类型分类](#日志类型分类)
      - [容器日志特点](#容器日志特点)
    - [1.2 日志管理挑战](#12-日志管理挑战)
      - [技术挑战](#技术挑战)
      - [运维挑战](#运维挑战)
    - [1.3 日志管理架构](#13-日志管理架构)
      - [日志管理架构层次](#日志管理架构层次)
  - [2. 容器日志收集](#2-容器日志收集)
    - [2.1 日志收集方式](#21-日志收集方式)
      - [日志收集模式](#日志收集模式)
      - [日志收集位置](#日志收集位置)
    - [2.2 日志收集工具](#22-日志收集工具)
      - [Fluentd](#fluentd)
- [Fluentd配置](#fluentd配置)
      - [Filebeat](#filebeat)
- [Filebeat配置](#filebeat配置)
      - [Logstash](#logstash)
- [Logstash配置](#logstash配置)
    - [2.3 日志收集配置](#23-日志收集配置)
      - [Docker日志驱动配置](#docker日志驱动配置)
      - [Kubernetes日志收集配置](#kubernetes日志收集配置)
  - [3. 日志存储与管理](#3-日志存储与管理)
    - [3.1 日志存储策略](#31-日志存储策略)
      - [存储分层策略](#存储分层策略)
      - [存储格式选择](#存储格式选择)
    - [3.2 日志索引与检索](#32-日志索引与检索)
      - [Elasticsearch索引策略](#elasticsearch索引策略)
      - [日志查询示例](#日志查询示例)
    - [3.3 日志生命周期管理](#33-日志生命周期管理)
      - [日志保留策略](#日志保留策略)
- [Elasticsearch ILM策略](#elasticsearch-ilm策略)
  - [4. 日志分析与处理](#4-日志分析与处理)
    - [4.1 日志解析与结构化](#41-日志解析与结构化)
      - [日志解析规则](#日志解析规则)
- [Logstash Grok模式](#logstash-grok模式)
- [自定义Grok模式](#自定义grok模式)
      - [日志结构化处理](#日志结构化处理)
- [Python日志结构化](#python日志结构化)
- [配置日志](#配置日志)
    - [4.2 日志聚合与分析](#42-日志聚合与分析)
      - [日志聚合查询](#日志聚合查询)
      - [实时日志分析](#实时日志分析)
- [实时日志分析](#实时日志分析)
    - [4.3 异常检测与告警](#43-异常检测与告警)
      - [异常检测规则](#异常检测规则)
- [Elasticsearch Watcher配置](#elasticsearch-watcher配置)
  - [5. 日志可视化与展示](#5-日志可视化与展示)
    - [5.1 日志仪表板](#51-日志仪表板)
      - [Kibana仪表板配置](#kibana仪表板配置)
      - [Grafana日志面板](#grafana日志面板)
    - [5.2 日志搜索与过滤](#52-日志搜索与过滤)
      - [高级搜索语法](#高级搜索语法)
      - [日志过滤规则](#日志过滤规则)
- [Fluentd过滤配置](#fluentd过滤配置)
    - [5.3 日志报表与导出](#53-日志报表与导出)
      - [自动报表生成](#自动报表生成)
- [日志报表生成](#日志报表生成)
  - [6. 日志安全与合规](#6-日志安全与合规)
    - [6.1 日志安全策略](#61-日志安全策略)
      - [敏感信息脱敏](#敏感信息脱敏)
- [Logstash脱敏配置](#logstash脱敏配置)
      - [访问控制](#访问控制)
- [Elasticsearch安全配置](#elasticsearch安全配置)
    - [6.2 日志审计与合规](#62-日志审计与合规)
      - [审计日志配置](#审计日志配置)
- [审计日志配置](#审计日志配置)
      - [合规性检查](#合规性检查)
- [合规性检查脚本](#合规性检查脚本)
    - [6.3 日志加密与保护](#63-日志加密与保护)
      - [传输加密](#传输加密)
- [TLS配置](#tls配置)
      - [存储加密](#存储加密)
- [存储加密配置](#存储加密配置)
  - [7. 性能优化与成本控制](#7-性能优化与成本控制)
    - [7.1 日志性能优化](#71-日志性能优化)
      - [日志收集优化](#日志收集优化)
- [Fluentd性能优化](#fluentd性能优化)
      - [存储优化](#存储优化)
    - [7.2 存储成本优化](#72-存储成本优化)
      - [数据压缩](#数据压缩)
- [数据压缩配置](#数据压缩配置)
      - [存储分层](#存储分层)
- [存储分层配置](#存储分层配置)
    - [7.3 网络带宽优化](#73-网络带宽优化)
      - [日志压缩](#日志压缩)
- [网络压缩配置](#网络压缩配置)
      - [批量传输](#批量传输)
- [批量传输配置](#批量传输配置)
  - [8. 实践案例](#8-实践案例)
    - [8.1 微服务日志管理](#81-微服务日志管理)
      - [微服务日志架构](#微服务日志架构)
- [微服务日志收集配置](#微服务日志收集配置)
    - [8.2 大规模集群日志管理](#82-大规模集群日志管理)
      - [大规模集群日志架构](#大规模集群日志架构)
    - [8.3 混合云日志管理](#83-混合云日志管理)
      - [混合云日志配置](#混合云日志配置)
- [混合云日志收集配置](#混合云日志收集配置)
  - [9. 最佳实践](#9-最佳实践)
    - [9.1 日志设计原则](#91-日志设计原则)
      - [日志设计原则](#日志设计原则)
      - [日志级别使用](#日志级别使用)
    - [9.2 日志管理策略](#92-日志管理策略)
      - [日志管理策略](#日志管理策略)
    - [9.3 故障排查指南](#93-故障排查指南)
      - [故障排查步骤](#故障排查步骤)
      - [常用排查命令](#常用排查命令)
- [查看容器日志](#查看容器日志)
- [查看Kubernetes Pod日志](#查看kubernetes-pod日志)
- [查看实时日志](#查看实时日志)
- [查看多容器Pod日志](#查看多容器pod日志)
- [查看历史日志](#查看历史日志)
  - [10. 未来发展趋势](#10-未来发展趋势)
    - [10.1 技术发展趋势](#101-技术发展趋势)
    - [10.2 应用发展趋势](#102-应用发展趋势)
  - [11. 总结](#11-总结)

- [容器日志管理深度解析](#容器日志管理深度解析)
  - [1. 容器日志概述](#1-容器日志概述)
    - [1.1 日志类型与特点](#11-日志类型与特点)
      - [日志类型分类](#日志类型分类)
      - [容器日志特点](#容器日志特点)
    - [1.2 日志管理挑战](#12-日志管理挑战)
      - [技术挑战](#技术挑战)
      - [运维挑战](#运维挑战)
    - [1.3 日志管理架构](#13-日志管理架构)
      - [日志管理架构层次](#日志管理架构层次)
  - [2. 容器日志收集](#2-容器日志收集)
    - [2.1 日志收集方式](#21-日志收集方式)
      - [日志收集模式](#日志收集模式)
      - [日志收集位置](#日志收集位置)
    - [2.2 日志收集工具](#22-日志收集工具)
      - [Fluentd](#fluentd)
- [Fluentd配置](#fluentd配置)
      - [Filebeat](#filebeat)
- [Filebeat配置](#filebeat配置)
      - [Logstash](#logstash)
- [Logstash配置](#logstash配置)
    - [2.3 日志收集配置](#23-日志收集配置)
      - [Docker日志驱动配置](#docker日志驱动配置)
      - [Kubernetes日志收集配置](#kubernetes日志收集配置)
  - [3. 日志存储与管理](#3-日志存储与管理)
    - [3.1 日志存储策略](#31-日志存储策略)
      - [存储分层策略](#存储分层策略)
      - [存储格式选择](#存储格式选择)
    - [3.2 日志索引与检索](#32-日志索引与检索)
      - [Elasticsearch索引策略](#elasticsearch索引策略)
      - [日志查询示例](#日志查询示例)
    - [3.3 日志生命周期管理](#33-日志生命周期管理)
      - [日志保留策略](#日志保留策略)
- [Elasticsearch ILM策略](#elasticsearch-ilm策略)
  - [4. 日志分析与处理](#4-日志分析与处理)
    - [4.1 日志解析与结构化](#41-日志解析与结构化)
      - [日志解析规则](#日志解析规则)
- [Logstash Grok模式](#logstash-grok模式)
- [自定义Grok模式](#自定义grok模式)
      - [日志结构化处理](#日志结构化处理)
- [Python日志结构化](#python日志结构化)
- [配置日志](#配置日志)
    - [4.2 日志聚合与分析](#42-日志聚合与分析)
      - [日志聚合查询](#日志聚合查询)
      - [实时日志分析](#实时日志分析)
- [实时日志分析](#实时日志分析)
- [实时查询错误日志](#实时查询错误日志)
    - [4.3 异常检测与告警](#43-异常检测与告警)
      - [异常检测规则](#异常检测规则)
- [Elasticsearch Watcher配置](#elasticsearch-watcher配置)
  - [5. 日志可视化与展示](#5-日志可视化与展示)
    - [5.1 日志仪表板](#51-日志仪表板)
      - [Kibana仪表板配置](#kibana仪表板配置)
      - [Grafana日志面板](#grafana日志面板)
    - [5.2 日志搜索与过滤](#52-日志搜索与过滤)
      - [高级搜索语法](#高级搜索语法)
      - [日志过滤规则](#日志过滤规则)
- [Fluentd过滤配置](#fluentd过滤配置)
    - [5.3 日志报表与导出](#53-日志报表与导出)
      - [自动报表生成](#自动报表生成)
- [日志报表生成](#日志报表生成)
- [查询日志数据](#查询日志数据)
- [转换为DataFrame](#转换为dataframe)
- [生成报表](#生成报表)
- [生成图表](#生成图表)
  - [6. 日志安全与合规](#6-日志安全与合规)
    - [6.1 日志安全策略](#61-日志安全策略)
      - [敏感信息脱敏](#敏感信息脱敏)
- [Logstash脱敏配置](#logstash脱敏配置)
      - [访问控制](#访问控制)
- [Elasticsearch安全配置](#elasticsearch安全配置)
    - [6.2 日志审计与合规](#62-日志审计与合规)
      - [审计日志配置](#审计日志配置)
- [审计日志配置](#审计日志配置)
      - [合规性检查](#合规性检查)
- [合规性检查脚本](#合规性检查脚本)
    - [6.3 日志加密与保护](#63-日志加密与保护)
      - [传输加密](#传输加密)
- [TLS配置](#tls配置)
      - [存储加密](#存储加密)
- [存储加密配置](#存储加密配置)
  - [7. 性能优化与成本控制](#7-性能优化与成本控制)
    - [7.1 日志性能优化](#71-日志性能优化)
      - [日志收集优化](#日志收集优化)
- [Fluentd性能优化](#fluentd性能优化)
      - [存储优化](#存储优化)
    - [7.2 存储成本优化](#72-存储成本优化)
      - [数据压缩](#数据压缩)
- [数据压缩配置](#数据压缩配置)
      - [存储分层](#存储分层)
- [存储分层配置](#存储分层配置)
    - [7.3 网络带宽优化](#73-网络带宽优化)
      - [日志压缩](#日志压缩)
- [网络压缩配置](#网络压缩配置)
      - [批量传输](#批量传输)
- [批量传输配置](#批量传输配置)
  - [8. 实践案例](#8-实践案例)
    - [8.1 微服务日志管理](#81-微服务日志管理)
      - [微服务日志架构](#微服务日志架构)
- [微服务日志收集配置](#微服务日志收集配置)
    - [8.2 大规模集群日志管理](#82-大规模集群日志管理)
      - [大规模集群日志架构](#大规模集群日志架构)
    - [8.3 混合云日志管理](#83-混合云日志管理)
      - [混合云日志配置](#混合云日志配置)
- [混合云日志收集配置](#混合云日志收集配置)
  - [9. 最佳实践](#9-最佳实践)
    - [9.1 日志设计原则](#91-日志设计原则)
      - [日志设计原则](#日志设计原则)
      - [日志级别使用](#日志级别使用)
    - [9.2 日志管理策略](#92-日志管理策略)
      - [日志管理策略](#日志管理策略)
    - [9.3 故障排查指南](#93-故障排查指南)
      - [故障排查步骤](#故障排查步骤)
      - [常用排查命令](#常用排查命令)
- [查看容器日志](#查看容器日志)
- [查看Kubernetes Pod日志](#查看kubernetes-pod日志)
- [查看实时日志](#查看实时日志)
- [查看多容器Pod日志](#查看多容器pod日志)
- [查看历史日志](#查看历史日志)
  - [10. 未来发展趋势](#10-未来发展趋势)
    - [10.1 技术发展趋势](#101-技术发展趋势)
    - [10.2 应用发展趋势](#102-应用发展趋势)
  - [11. 总结](#11-总结)

- [容器日志管理深度解析](#容器日志管理深度解析)
  - [目录](#目录)
  - [1. 容器日志概述](#1-容器日志概述)
    - [1.1 日志类型与特点](#11-日志类型与特点)
    - [1.2 日志管理挑战](#12-日志管理挑战)
    - [1.3 日志管理架构](#13-日志管理架构)
  - [2. 容器日志收集](#2-容器日志收集)
    - [2.1 日志收集方式](#21-日志收集方式)
    - [2.2 日志收集工具](#22-日志收集工具)
    - [2.3 日志收集配置](#23-日志收集配置)
  - [3. 日志存储与管理](#3-日志存储与管理)
    - [3.1 日志存储策略](#31-日志存储策略)
    - [3.2 日志索引与检索](#32-日志索引与检索)
    - [3.3 日志生命周期管理](#33-日志生命周期管理)
  - [4. 日志分析与处理](#4-日志分析与处理)
    - [4.1 日志解析与结构化](#41-日志解析与结构化)
    - [4.2 日志聚合与分析](#42-日志聚合与分析)
    - [4.3 异常检测与告警](#43-异常检测与告警)
  - [5. 日志可视化与展示](#5-日志可视化与展示)
    - [5.1 日志仪表板](#51-日志仪表板)
    - [5.2 日志搜索与过滤](#52-日志搜索与过滤)
    - [5.3 日志报表与导出](#53-日志报表与导出)
  - [6. 日志安全与合规](#6-日志安全与合规)
    - [6.1 日志安全策略](#61-日志安全策略)
    - [6.2 日志审计与合规](#62-日志审计与合规)
    - [6.3 日志加密与保护](#63-日志加密与保护)
  - [7. 性能优化与成本控制](#7-性能优化与成本控制)
    - [7.1 日志性能优化](#71-日志性能优化)
    - [7.2 存储成本优化](#72-存储成本优化)
    - [7.3 网络带宽优化](#73-网络带宽优化)
  - [8. 实践案例](#8-实践案例)
    - [8.1 微服务日志管理](#81-微服务日志管理)
    - [8.2 大规模集群日志管理](#82-大规模集群日志管理)
    - [8.3 混合云日志管理](#83-混合云日志管理)
  - [9. 最佳实践](#9-最佳实践)
    - [9.1 日志设计原则](#91-日志设计原则)
    - [9.2 日志管理策略](#92-日志管理策略)
    - [9.3 故障排查指南](#93-故障排查指南)
  - [10. 未来发展趋势](#10-未来发展趋势)
  - [11. 总结](#11-总结)

## 1. 容器日志概述

### 1.1 日志类型与特点

#### 日志类型分类

1. **应用日志**
   - 业务逻辑日志
   - 错误日志
   - 调试日志
   - 访问日志

2. **系统日志**
   - 操作系统日志
   - 容器运行时日志
   - 网络日志
   - 存储日志

3. **审计日志**
   - 用户操作日志
   - 安全事件日志
   - 合规审计日志
   - 访问控制日志

#### 容器日志特点

1. **短暂性**: 容器生命周期短，日志需要及时收集
2. **分散性**: 日志分布在多个容器和节点上
3. **大量性**: 容器数量多，日志量巨大
4. **多样性**: 不同应用产生不同格式的日志

### 1.2 日志管理挑战

#### 技术挑战

1. **日志收集**: 如何高效收集分散的日志
2. **日志存储**: 如何存储大量日志数据
3. **日志检索**: 如何快速检索和分析日志
4. **日志安全**: 如何保护敏感日志信息

#### 运维挑战

1. **成本控制**: 日志存储和处理成本高
2. **性能影响**: 日志收集对应用性能的影响
3. **故障排查**: 如何快速定位问题
4. **合规要求**: 满足各种合规标准

### 1.3 日志管理架构

#### 日志管理架构层次

```text
┌─────────────────────────────────────────────────────────────┐
│                    应用层                                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   应用日志   │  │   系统日志   │  │   审计日志   │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    收集层                                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   Fluentd   │  │   Filebeat  │  │   Logstash  │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    存储层                                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │Elasticsearch│  │   InfluxDB  │  │   ClickHouse│         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    展示层                                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   Kibana    │  │   Grafana   │  │   Jaeger    │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

## 2. 容器日志收集

### 2.1 日志收集方式

#### 日志收集模式

1. **推模式**: 应用主动推送日志
2. **拉模式**: 收集器主动拉取日志
3. **混合模式**: 结合推拉模式

#### 日志收集位置

1. **容器内收集**: 在容器内部收集日志
2. **宿主机收集**: 在宿主机上收集容器日志
3. **边车模式**: 使用边车容器收集日志

### 2.2 日志收集工具

#### Fluentd

```yaml
    # Fluentd配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
      time_key time
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name fluentd
      type_name _doc
    </match>
```

#### Filebeat

```yaml
    # Filebeat配置
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
  - add_kubernetes_metadata:
      host: ${NODE_NAME}
      matchers:
      - logs_path:
          logs_path: "/var/log/containers/"

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "filebeat-%{+yyyy.MM.dd}"

setup.kibana:
  host: "kibana:5601"
```

#### Logstash

```ruby
    # Logstash配置
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][log_type] == "container" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
  }
}
```

### 2.3 日志收集配置

#### Docker日志驱动配置

```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
```

#### Kubernetes日志收集配置

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name kubernetes
    </match>
```

## 3. 日志存储与管理

### 3.1 日志存储策略

#### 存储分层策略

1. **热存储**: 近期日志，快速访问
2. **温存储**: 中期日志，中等访问速度
3. **冷存储**: 历史日志，低成本存储

#### 存储格式选择

1. **JSON格式**: 结构化存储，便于查询
2. **文本格式**: 原始格式，存储空间小
3. **二进制格式**: 压缩存储，节省空间

### 3.2 日志索引与检索

#### Elasticsearch索引策略

```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index": {
      "lifecycle": {
        "name": "logs-policy",
        "rollover_alias": "logs"
      }
    }
  },
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "message": {
        "type": "text",
        "analyzer": "standard"
      },
      "level": {
        "type": "keyword"
      },
      "service": {
        "type": "keyword"
      },
      "container_id": {
        "type": "keyword"
      }
    }
  }
}
```

#### 日志查询示例

```json
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "@timestamp": {
              "gte": "now-1h",
              "lte": "now"
            }
          }
        },
        {
          "term": {
            "level": "ERROR"
          }
        }
      ]
    }
  },
  "sort": [
    {
      "@timestamp": {
        "order": "desc"
      }
    }
  ]
}
```

### 3.3 日志生命周期管理

#### 日志保留策略

```yaml
    # Elasticsearch ILM策略
PUT _ilm/policy/logs-policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "10GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "1d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "cold": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "30d"
      }
    }
  }
}
```

## 4. 日志分析与处理

### 4.1 日志解析与结构化

#### 日志解析规则

```ruby
    # Logstash Grok模式
grok {
  match => { 
    "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread}\] %{DATA:logger} - %{GREEDYDATA:message}" 
  }
}

    # 自定义Grok模式
grok {
  match => { 
    "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:service} %{WORD:method} %{URIPATH:path} %{NUMBER:status} %{NUMBER:duration}ms" 
  }
}
```

#### 日志结构化处理

```python
    # Python日志结构化
import json
import logging
from datetime import datetime

class StructuredFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        return json.dumps(log_entry)

    # 配置日志
logger = logging.getLogger()
handler = logging.StreamHandler()
handler.setFormatter(StructuredFormatter())
logger.addHandler(handler)
```

### 4.2 日志聚合与分析

#### 日志聚合查询

```json
{
  "size": 0,
  "aggs": {
    "error_count": {
      "filter": {
        "term": {
          "level": "ERROR"
        }
      }
    },
    "services": {
      "terms": {
        "field": "service",
        "size": 10
      },
      "aggs": {
        "error_rate": {
          "filter": {
            "term": {
              "level": "ERROR"
            }
          }
        }
      }
    },
    "time_series": {
      "date_histogram": {
        "field": "@timestamp",
        "interval": "1h"
      },
      "aggs": {
        "error_count": {
          "filter": {
            "term": {
              "level": "ERROR"
            }
          }
        }
      }
    }
  }
}
```

#### 实时日志分析

```python
    # 实时日志分析
from elasticsearch import Elasticsearch
import json

def analyze_logs():
    es = Elasticsearch(['localhost:9200'])
    
    # 实时查询错误日志
    query = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"level": "ERROR"}},
                    {"range": {"@timestamp": {"gte": "now-5m"}}}
                ]
            }
        },
        "size": 100
    }
    
    response = es.search(index="logs-*", body=query)
    
    for hit in response['hits']['hits']:
        log_entry = hit['_source']
        print(f"Error in {log_entry['service']}: {log_entry['message']}")
```

### 4.3 异常检测与告警

#### 异常检测规则

```yaml
    # Elasticsearch Watcher配置
PUT _watcher/watch/error_alert
{
  "trigger": {
    "schedule": {
      "interval": "1m"
    }
  },
  "input": {
    "search": {
      "request": {
        "search_type": "query_then_fetch",
        "indices": ["logs-*"],
        "body": {
          "query": {
            "bool": {
              "must": [
                {"term": {"level": "ERROR"}},
                {"range": {"@timestamp": {"gte": "now-5m"}}}
              ]
            }
          }
        }
      }
    }
  },
  "condition": {
    "compare": {
      "ctx.payload.hits.total": {
        "gt": 10
      }
    }
  },
  "actions": {
    "send_alert": {
      "webhook": {
        "scheme": "https",
        "host": "hooks.slack.com",
        "port": 443,
        "path": "/services/YOUR/SLACK/WEBHOOK",
        "method": "post",
        "body": "{\"text\": \"High error rate detected: {{ctx.payload.hits.total}} errors in the last 5 minutes\"}"
      }
    }
  }
}
```

## 5. 日志可视化与展示

### 5.1 日志仪表板

#### Kibana仪表板配置

```json
{
  "dashboard": {
    "title": "Container Logs Dashboard",
    "panels": [
      {
        "title": "Error Logs Over Time",
        "type": "histogram",
        "params": {
          "query": {
            "query_string": {
              "query": "level:ERROR"
            }
          },
          "date_field": "@timestamp",
          "interval": "1h"
        }
      },
      {
        "title": "Top Error Services",
        "type": "pie",
        "params": {
          "query": {
            "query_string": {
              "query": "level:ERROR"
            }
          },
          "field": "service",
          "size": 10
        }
      }
    ]
  }
}
```

#### Grafana日志面板

```json
{
  "dashboard": {
    "title": "Container Logs",
    "panels": [
      {
        "title": "Log Volume",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(logstash_logs_total[5m])",
            "legendFormat": "{{service}}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(logstash_logs_total{level=\"ERROR\"}[5m]) / rate(logstash_logs_total[5m]) * 100",
            "legendFormat": "Error Rate %"
          }
        ]
      }
    ]
  }
}
```

### 5.2 日志搜索与过滤

#### 高级搜索语法

```json
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "@timestamp": {
              "gte": "now-1h",
              "lte": "now"
            }
          }
        }
      ],
      "should": [
        {
          "match": {
            "message": "error"
          }
        },
        {
          "match": {
            "message": "exception"
          }
        }
      ],
      "filter": [
        {
          "term": {
            "service": "api-gateway"
          }
        }
      ]
    }
  }
}
```

#### 日志过滤规则

```yaml
    # Fluentd过滤配置
<filter kubernetes.**>
  @type grep
  <regexp>
    key level
    pattern /ERROR|WARN/
  </regexp>
</filter>

<filter kubernetes.**>
  @type record_transformer
  <record>
    environment "#{ENV['ENVIRONMENT']}"
    cluster "#{ENV['CLUSTER_NAME']}"
  </record>
</filter>
```

### 5.3 日志报表与导出

#### 自动报表生成

```python
    # 日志报表生成
import pandas as pd
from elasticsearch import Elasticsearch
import matplotlib.pyplot as plt

def generate_log_report():
    es = Elasticsearch(['localhost:9200'])
    
    # 查询日志数据
    query = {
        "query": {
            "range": {
                "@timestamp": {
                    "gte": "now-1d",
                    "lte": "now"
                }
            }
        },
        "size": 10000
    }
    
    response = es.search(index="logs-*", body=query)
    
    # 转换为DataFrame
    logs = []
    for hit in response['hits']['hits']:
        logs.append(hit['_source'])
    
    df = pd.DataFrame(logs)
    
    # 生成报表
    report = {
        'total_logs': len(df),
        'error_count': len(df[df['level'] == 'ERROR']),
        'warning_count': len(df[df['level'] == 'WARN']),
        'top_services': df['service'].value_counts().head(10).to_dict()
    }
    
    # 生成图表
    df['level'].value_counts().plot(kind='bar')
    plt.title('Log Level Distribution')
    plt.savefig('log_level_distribution.png')
    
    return report
```

## 6. 日志安全与合规

### 6.1 日志安全策略

#### 敏感信息脱敏

```ruby
    # Logstash脱敏配置
filter {
  mutate {
    gsub => [
      "message", "password=\w+", "password=***",
      "message", "token=\w+", "token=***",
      "message", "key=\w+", "key=***"
    ]
  }
}
```

#### 访问控制

```yaml
    # Elasticsearch安全配置
xpack.security.enabled: true
xpack.security.authc:
  realms:
    native:
      native1:
        order: 0
xpack.security.authz:
  roles:
    log_viewer:
      cluster: ["monitor"]
      indices:
        - names: ["logs-*"]
          privileges: ["read"]
```

### 6.2 日志审计与合规

#### 审计日志配置

```yaml
    # 审计日志配置
audit:
  enabled: true
  log_file_path: /var/log/elasticsearch/audit.log
  events:
    - access_granted
    - access_denied
    - authentication_failed
    - connection_granted
    - connection_denied
```

#### 合规性检查

```python
    # 合规性检查脚本
def compliance_check():
    checks = {
        'log_retention': check_log_retention(),
        'access_control': check_access_control(),
        'encryption': check_encryption(),
        'audit_trail': check_audit_trail()
    }
    
    for check, result in checks.items():
        if not result:
            print(f"Compliance check failed: {check}")
    
    return all(checks.values())
```

### 6.3 日志加密与保护

#### 传输加密

```yaml
    # TLS配置
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.key: /path/to/elasticsearch.key
xpack.security.transport.ssl.certificate: /path/to/elasticsearch.crt
```

#### 存储加密

```yaml
    # 存储加密配置
xpack.security.encryption_key: "your-encryption-key"
```

## 7. 性能优化与成本控制

### 7.1 日志性能优化

#### 日志收集优化

```yaml
    # Fluentd性能优化
<system>
  workers 4
  root_dir /tmp/fluentd
  log_level info
</system>

<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  read_from_head false
  refresh_interval 5
</source>
```

#### 存储优化

```json
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "refresh_interval": "30s",
      "translog": {
        "durability": "async",
        "sync_interval": "5s"
      }
    }
  }
}
```

### 7.2 存储成本优化

#### 数据压缩

```yaml
    # 数据压缩配置
index.codec: best_compression
```

#### 存储分层

```yaml
    # 存储分层配置
PUT _ilm/policy/cost-optimized
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "5GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "1d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          },
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "cold": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "30d"
      }
    }
  }
}
```

### 7.3 网络带宽优化

#### 日志压缩

```yaml
    # 网络压缩配置
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  compression_level: 6
  compression: gzip
```

#### 批量传输

```yaml
    # 批量传输配置
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  bulk_max_size: 1000
  bulk_timeout: 5s
```

## 8. 实践案例

### 8.1 微服务日志管理

#### 微服务日志架构

```yaml
    # 微服务日志收集配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: microservice-logging
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    <filter kubernetes.**>
      @type record_transformer
      <record>
        service_name ${record["kubernetes"]["labels"]["app"]}
        service_version ${record["kubernetes"]["labels"]["version"]}
        environment ${record["kubernetes"]["labels"]["environment"]}
      </record>
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name microservice-logs
    </match>
```

### 8.2 大规模集群日志管理

#### 大规模集群日志架构

```text
┌─────────────────────────────────────────────────────────────┐
│                    日志收集层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   Node 1    │  │   Node 2    │  │   Node N    │         │
│  │  Fluentd    │  │  Fluentd    │  │  Fluentd    │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    日志聚合层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  Fluentd    │  │  Fluentd    │  │  Fluentd    │         │
│  │  Aggregator │  │  Aggregator │  │  Aggregator │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    日志存储层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │Elasticsearch│  │Elasticsearch│  │Elasticsearch│         │
│  │   Cluster   │  │   Cluster   │  │   Cluster   │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

### 8.3 混合云日志管理

#### 混合云日志配置

```yaml
    # 混合云日志收集配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: hybrid-cloud-logging
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    <filter kubernetes.**>
      @type record_transformer
      <record>
        cloud_provider "#{ENV['CLOUD_PROVIDER']}"
        region "#{ENV['REGION']}"
        cluster_name "#{ENV['CLUSTER_NAME']}"
      </record>
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name hybrid-cloud-logs
    </match>
```

## 9. 最佳实践

### 9.1 日志设计原则

#### 日志设计原则

1. **结构化**: 使用结构化格式（JSON）
2. **一致性**: 保持日志格式的一致性
3. **可读性**: 确保日志的可读性
4. **完整性**: 包含足够的上下文信息

#### 日志级别使用

1. **ERROR**: 系统错误，需要立即处理
2. **WARN**: 警告信息，需要关注
3. **INFO**: 一般信息，记录重要事件
4. **DEBUG**: 调试信息，开发时使用

### 9.2 日志管理策略

#### 日志管理策略

1. **集中化**: 集中收集和管理日志
2. **标准化**: 统一日志格式和标准
3. **自动化**: 自动化日志处理和分析
4. **安全化**: 保护敏感日志信息

### 9.3 故障排查指南

#### 故障排查步骤

1. **确认问题**: 确认故障现象和影响范围
2. **收集日志**: 收集相关日志信息
3. **分析日志**: 分析日志找出问题原因
4. **解决问题**: 根据分析结果解决问题
5. **总结经验**: 总结故障处理经验

#### 常用排查命令

```bash
    # 查看容器日志
docker logs container_name

    # 查看Kubernetes Pod日志
kubectl logs pod_name

    # 查看实时日志
kubectl logs -f pod_name

    # 查看多容器Pod日志
kubectl logs pod_name -c container_name

    # 查看历史日志
kubectl logs pod_name --previous
```

## 10. 未来发展趋势

### 10.1 技术发展趋势

1. **AI驱动的日志分析**: 使用机器学习提高日志分析能力
2. **实时日志处理**: 提高日志处理的实时性
3. **边缘日志管理**: 支持边缘计算环境的日志管理
4. **云原生日志**: 深度集成云原生技术栈

### 10.2 应用发展趋势

1. **智能告警**: 基于AI的智能告警系统
2. **预测性分析**: 基于历史日志的预测分析
3. **自动化运维**: 基于日志的自动化运维
4. **业务洞察**: 从日志中提取业务洞察

## 11. 总结

容器日志管理是现代容器化环境的重要组成部分，它通过集中化的日志收集、存储、分析和展示，为容器化应用提供全面的可观测性。随着容器技术的不断发展，日志管理技术也在不断演进，从传统的文本日志发展到结构化的JSON日志，从简单的日志收集发展到智能化的日志分析。

未来，容器日志管理将更加智能化、自动化，通过AI技术提高日志分析的准确性和效率，通过云原生技术提供更好的扩展性和可靠性。同时，日志管理也将更加关注业务价值和用户体验，为企业数字化转型提供有力支撑。
