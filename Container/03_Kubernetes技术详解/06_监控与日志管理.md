# 监控与日志管理

## 目录

- [监控与日志管理](#监控与日志管理)
  - [目录](#目录)
  - [1. 监控指标与采集](#1-监控指标与采集)
  - [2. 可视化与告警](#2-可视化与告警)
  - [3. 日志采集与处理](#3-日志采集与处理)
  - [4. 分布式追踪](#4-分布式追踪)
  - [5. 实践要点与 FAQ](#5-实践要点与-faq)
  - [6. 故障清单与排查](#6-故障清单与排查)
  - [7. 示例清单与 SOP](#7-示例清单与-sop)
  - [8. 告警/事件映射表](#8-告警事件映射表)
  - [9. Alert 规则模板](#9-alert-规则模板)

## 证据落盘到 artifacts/observability（新增）

- 目的：统一留存监控/日志/追踪的关键证据，支撑审计、回溯与容量规划。
- 目录建议：`artifacts/YYYY-MM-DD/observability/`，包含：
  - metrics/（原始导出 CSV/JSON、仪表盘快照 PNG/SVG）
  - logs/（聚合查询结果、错误样本、索引统计）
  - traces/（端到端关键链路样本与摘要）
  - alerts/（规则与近 N 日告警快照）
  - manifest.json 与 `*.sha256`
- 标准锚点：版本/工具链请统一参考《2025年技术标准最终对齐报告.md》。

## 1. 监控指标与采集

- Metrics Server、Prometheus、kube-state-metrics

## 2. 可视化与告警

- Grafana 仪表盘与 Alertmanager 告警

## 3. 日志采集与处理

- Fluent Bit/Fluentd/Vector、Elasticsearch/OpenSearch

## 4. 分布式追踪

- OpenTelemetry、Tempo/Jaeger

## 5. 实践要点与 FAQ

- 多租户监控、成本与存储优化、SLO/SLA 对齐

（待补充：参考部署清单）

## 6. 故障清单与排查

- 指标缺失：核对 ServiceMonitor/PodMonitor 与命名空间/标签选择器。
- 告警不触发/风暴：阈值与抑制、告警路由与静默配置。
- 日志采集异常：DaemonSet 权限、缓冲与背压、索引生命周期策略。

## 7. 示例清单与 SOP

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: web
  endpoints:
  - port: metrics
    interval: 15s
```

SOP：

- 关联关系：确认 Prometheus Operator、CRDs 与 Selector 对齐。
- 告警路由：检查 Alertmanager 路由/接收器与静默规则。

## 8. 告警/事件映射表

| 监控信号 | 典型事件/症状 | 可能原因 | 定位要点 |
|---|---|---|---|
| Pod 可用性 | CrashLoopBackOff/重启频繁 | 探针/依赖/资源不足 | 查看容器日志与事件、相关 Service |
| 资源压力 | 高 CPU/内存使用、OOMKilled | limits 不当/泄漏 | 结合 Pod/Node 指标与 cgroup 限额 |
| 网络连通性 | 超时/5xx 增加 | NetworkPolicy/Ingress/LB | 核对策略与路由、端点可达性 |
| 存储异常 | I/O 延迟升高、挂载失败 | CSI/底盘性能/权限 | 查看 CSI 控制器与节点插件日志 |
| 控制面健康 | API 错误率上升/etcd 延迟 | 负载或故障 | 观测 apiserver/etcd 指标与事件 |

## 9. Alert 规则模板

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: k8s-critical-alerts
spec:
  groups:
  - name: k8s.pod.availability
    rules:
    - alert: PodRestartBurst
      expr: increase(kube_pod_container_status_restarts_total[5m]) > 3
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: Pod restart burst detected
        description: Pod {{ $labels.pod }} in ns {{ $labels.namespace }} restarted >3 in 5m.
  - name: k8s.node.resources
    rules:
    - alert: NodeMemoryPressure
      expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
      for: 15m
      labels:
        severity: critical
      annotations:
        summary: Node memory pressure > 90%
        description: Node {{ $labels.instance }} memory pressure sustained.
```
