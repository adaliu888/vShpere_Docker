#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆæµ‹è¯•
æä¾›å®Œæ•´çš„ç³»ç»Ÿé›†æˆæµ‹è¯•ï¼ŒéªŒè¯æ‰€æœ‰ç»„ä»¶ååŒå·¥ä½œ
"""

import os
import sys
import json
import time
import subprocess
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import argparse
from dataclasses import dataclass, asdict
import concurrent.futures
import threading

@dataclass
class IntegrationTestResult:
    """é›†æˆæµ‹è¯•ç»“æœ"""
    test_name: str
    status: str  # "passed", "failed", "error"
    duration: float
    message: str
    components_tested: List[str]
    details: Dict[str, Any] = None

class IntegrationTests:
    """é›†æˆæµ‹è¯•"""
    
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.tools_dir = self.root_dir / "tools"
        self.test_results = []
        
        # åˆ›å»ºæµ‹è¯•ç›®å½•
        self.test_dir = self.root_dir / "tools" / "tests"
        self.test_dir.mkdir(parents=True, exist_ok=True)
        
        # æµ‹è¯•ç¯å¢ƒ
        self.test_env = None
        
    def setup_test_environment(self) -> bool:
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
            self.test_env = tempfile.mkdtemp(prefix="integration_test_")
            self.test_env_path = Path(self.test_env)
            
            # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
            self._create_test_documents()
            
            print(f"âœ… æµ‹è¯•ç¯å¢ƒå·²è®¾ç½®: {self.test_env}")
            return True
            
        except Exception as e:
            print(f"âŒ è®¾ç½®æµ‹è¯•ç¯å¢ƒå¤±è´¥: {e}")
            return False
    
    def teardown_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            if self.test_env and Path(self.test_env).exists():
                shutil.rmtree(self.test_env)
                print("âœ… æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æµ‹è¯•ç¯å¢ƒå¤±è´¥: {e}")
    
    def _create_test_documents(self):
        """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
        test_docs = [
            {
                "name": "test_doc_1.md",
                "content": """# æµ‹è¯•æ–‡æ¡£1

## æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯ç³»ç»ŸåŠŸèƒ½ã€‚

## æŠ€æœ¯æ¶æ„

### ç³»ç»Ÿè®¾è®¡

ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ã€‚

### æ•°æ®æµ

æ•°æ®æµå‘å¦‚ä¸‹ï¼š

1. è¾“å…¥å¤„ç†
2. æ•°æ®å¤„ç†
3. è¾“å‡ºç”Ÿæˆ

## å®ç°æ–¹æ¡ˆ

### æ ¸å¿ƒæ¨¡å—

- å¤„ç†æ¨¡å—
- å­˜å‚¨æ¨¡å—
- æ¥å£æ¨¡å—

## æµ‹è¯•éªŒè¯

### åŠŸèƒ½æµ‹è¯•

æµ‹è¯•å„é¡¹åŠŸèƒ½æ˜¯å¦æ­£å¸¸ã€‚

### æ€§èƒ½æµ‹è¯•

æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ã€‚

## æ€»ç»“

æœ¬æ–‡æ¡£éªŒè¯äº†ç³»ç»Ÿçš„åŸºæœ¬åŠŸèƒ½ã€‚
"""
            },
            {
                "name": "test_doc_2.md",
                "content": """# æµ‹è¯•æ–‡æ¡£2

## é¡¹ç›®èƒŒæ™¯

é¡¹ç›®æ—¨åœ¨è§£å†³æ–‡æ¡£ç®¡ç†é—®é¢˜ã€‚

## éœ€æ±‚åˆ†æ

### åŠŸèƒ½éœ€æ±‚

1. æ–‡æ¡£åˆ›å»º
2. æ–‡æ¡£ç¼–è¾‘
3. æ–‡æ¡£ç®¡ç†

### éåŠŸèƒ½éœ€æ±‚

- æ€§èƒ½è¦æ±‚
- å®‰å…¨è¦æ±‚
- å¯ç”¨æ€§è¦æ±‚

## è®¾è®¡æ–¹æ¡ˆ

### æ¶æ„è®¾è®¡

é‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡ã€‚

### æŠ€æœ¯é€‰å‹

é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆã€‚

## å®æ–½è®¡åˆ’

### å¼€å‘è®¡åˆ’

åˆ†é˜¶æ®µå¼€å‘å®æ–½ã€‚

### æµ‹è¯•è®¡åˆ’

åˆ¶å®šè¯¦ç»†çš„æµ‹è¯•è®¡åˆ’ã€‚

## é£é™©è¯„ä¼°

è¯†åˆ«å’Œè¯„ä¼°é¡¹ç›®é£é™©ã€‚

## é¡¹ç›®æ€»ç»“

æ€»ç»“é¡¹ç›®ç»éªŒå’Œæ•™è®­ã€‚
"""
            },
            {
                "name": "test_doc_3.md",
                "content": """# æµ‹è¯•æ–‡æ¡£3

## ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•æ–‡æ¡£ã€‚

## å†…å®¹

åŒ…å«åŸºæœ¬çš„å†…å®¹ç»“æ„ã€‚

## ç»“è®º

æ–‡æ¡£æµ‹è¯•å®Œæˆã€‚
"""
            }
        ]
        
        for doc in test_docs:
            doc_path = self.test_env_path / doc["name"]
            with open(doc_path, 'w', encoding='utf-8') as f:
                f.write(doc["content"])
    
    def run_integration_test(self, test_func, test_name: str, components: List[str]) -> IntegrationTestResult:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        start_time = time.time()
        
        try:
            result = test_func()
            duration = time.time() - start_time
            
            if result is True:
                return IntegrationTestResult(
                    test_name=test_name,
                    status="passed",
                    duration=duration,
                    message="æµ‹è¯•é€šè¿‡",
                    components_tested=components
                )
            elif result is False:
                return IntegrationTestResult(
                    test_name=test_name,
                    status="failed",
                    duration=duration,
                    message="æµ‹è¯•å¤±è´¥",
                    components_tested=components
                )
            else:
                return IntegrationTestResult(
                    test_name=test_name,
                    status="passed",
                    duration=duration,
                    message=str(result),
                    components_tested=components
                )
                
        except Exception as e:
            duration = time.time() - start_time
            return IntegrationTestResult(
                test_name=test_name,
                status="error",
                duration=duration,
                message=f"æµ‹è¯•é”™è¯¯: {str(e)}",
                components_tested=components,
                details={"exception": str(e), "type": type(e).__name__}
            )
    
    def test_complete_workflow(self) -> bool:
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        try:
            # 1. è¿è¡Œç›®å½•æ›´æ–°
            toc_result = subprocess.run([
                sys.executable, str(self.tools_dir / "simple_toc_updater.py"), str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if toc_result.returncode != 0:
                print(f"âŒ ç›®å½•æ›´æ–°å¤±è´¥: {toc_result.stderr}")
                return False
            
            # 2. è¿è¡Œè´¨é‡æ£€æŸ¥
            quality_result = subprocess.run([
                sys.executable, str(self.tools_dir / "document_automation.py"), 
                "--validate", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            # è´¨é‡æ£€æŸ¥å¯èƒ½è¿”å›éé›¶ç ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            print(f"è´¨é‡æ£€æŸ¥ç»“æœ: {quality_result.returncode}")
            
            # 3. è¿è¡Œç»¼åˆè‡ªåŠ¨åŒ–
            comprehensive_result = subprocess.run([
                sys.executable, str(self.tools_dir / "comprehensive_automation.py"), 
                "--mode", "quick", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=60)
            
            if comprehensive_result.returncode != 0:
                print(f"âŒ ç»¼åˆè‡ªåŠ¨åŒ–å¤±è´¥: {comprehensive_result.stderr}")
                return False
            
            # 4. éªŒè¯ç»“æœ
            for doc_file in self.test_env_path.glob("*.md"):
                content = doc_file.read_text(encoding='utf-8')
                if "## ç›®å½•" not in content:
                    print(f"âŒ æ–‡æ¡£ç¼ºå°‘ç›®å½•: {doc_file.name}")
                    return False
            
            print("âœ… å®Œæ•´å·¥ä½œæµæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_backup_restore_workflow(self) -> bool:
        """æµ‹è¯•å¤‡ä»½æ¢å¤å·¥ä½œæµ"""
        try:
            # 1. åˆ›å»ºå¤‡ä»½
            backup_result = subprocess.run([
                sys.executable, str(self.tools_dir / "backup_system.py"), 
                "--create", "test_backup", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if backup_result.returncode != 0:
                print(f"âŒ åˆ›å»ºå¤‡ä»½å¤±è´¥: {backup_result.stderr}")
                return False
            
            # 2. ä¿®æ”¹æ–‡æ¡£
            test_doc = self.test_env_path / "test_doc_1.md"
            original_content = test_doc.read_text(encoding='utf-8')
            modified_content = original_content + "\n\n## æ–°å¢ç« èŠ‚\n\nè¿™æ˜¯æ–°å¢çš„å†…å®¹ã€‚\n"
            test_doc.write_text(modified_content, encoding='utf-8')
            
            # 3. æ¢å¤å¤‡ä»½
            restore_result = subprocess.run([
                sys.executable, str(self.tools_dir / "backup_system.py"), 
                "--restore", "test_backup", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if restore_result.returncode != 0:
                print(f"âŒ æ¢å¤å¤‡ä»½å¤±è´¥: {restore_result.stderr}")
                return False
            
            # 4. éªŒè¯æ¢å¤ç»“æœ
            restored_content = test_doc.read_text(encoding='utf-8')
            if restored_content != original_content:
                print("âŒ å¤‡ä»½æ¢å¤éªŒè¯å¤±è´¥")
                return False
            
            print("âœ… å¤‡ä»½æ¢å¤å·¥ä½œæµæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½æ¢å¤å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_monitoring_integration(self) -> bool:
        """æµ‹è¯•ç›‘æ§é›†æˆ"""
        try:
            # 1. å¯åŠ¨ç›‘æ§
            monitoring_result = subprocess.run([
                sys.executable, str(self.tools_dir / "monitoring_system.py"), 
                "--start", "--duration", "10", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=20)
            
            # 2. è¿è¡Œä¸€äº›æ“ä½œ
            subprocess.run([
                sys.executable, str(self.tools_dir / "simple_toc_updater.py"), str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            # 3. ç”Ÿæˆç›‘æ§æŠ¥å‘Š
            report_result = subprocess.run([
                sys.executable, str(self.tools_dir / "monitoring_system.py"), 
                "--system-report", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if report_result.returncode != 0:
                print(f"âŒ ç”Ÿæˆç›‘æ§æŠ¥å‘Šå¤±è´¥: {report_result.stderr}")
                return False
            
            print("âœ… ç›‘æ§é›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ ç›‘æ§é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_template_system_integration(self) -> bool:
        """æµ‹è¯•æ¨¡æ¿ç³»ç»Ÿé›†æˆ"""
        try:
            # 1. åˆ›å»ºæ¨¡æ¿
            create_result = subprocess.run([
                sys.executable, str(self.tools_dir / "template_system.py"), 
                "--create", "test_template", "--description", "æµ‹è¯•æ¨¡æ¿", 
                "--category", "æŠ€æœ¯æ–‡æ¡£", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if create_result.returncode != 0:
                print(f"âŒ åˆ›å»ºæ¨¡æ¿å¤±è´¥: {create_result.stderr}")
                return False
            
            # 2. åº”ç”¨æ¨¡æ¿
            output_file = self.test_env_path / "generated_doc.md"
            apply_result = subprocess.run([
                sys.executable, str(self.tools_dir / "template_system.py"), 
                "--apply", "test_template", str(output_file), "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if apply_result.returncode != 0:
                print(f"âŒ åº”ç”¨æ¨¡æ¿å¤±è´¥: {apply_result.stderr}")
                return False
            
            # 3. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
            if not output_file.exists():
                print("âŒ æ¨¡æ¿åº”ç”¨åæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            content = output_file.read_text(encoding='utf-8')
            if len(content) < 100:  # åŸºæœ¬å†…å®¹æ£€æŸ¥
                print("âŒ ç”Ÿæˆçš„æ–‡ä»¶å†…å®¹è¿‡å°‘")
                return False
            
            print("âœ… æ¨¡æ¿ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡æ¿ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_performance_optimization_integration(self) -> bool:
        """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–é›†æˆ"""
        try:
            # 1. è¿è¡Œæ€§èƒ½ç›‘æ§
            monitor_result = subprocess.run([
                sys.executable, str(self.tools_dir / "performance_optimizer.py"), 
                "--monitor", "--duration", "10", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=20)
            
            # 2. è¿è¡Œæ€§èƒ½åˆ†æ
            analyze_result = subprocess.run([
                sys.executable, str(self.tools_dir / "performance_optimizer.py"), 
                "--analyze", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if analyze_result.returncode != 0:
                print(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {analyze_result.stderr}")
                return False
            
            # 3. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            report_result = subprocess.run([
                sys.executable, str(self.tools_dir / "performance_optimizer.py"), 
                "--report", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=30)
            
            if report_result.returncode != 0:
                print(f"âŒ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {report_result.stderr}")
                return False
            
            print("âœ… æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_validation_suite_integration(self) -> bool:
        """æµ‹è¯•éªŒè¯å¥—ä»¶é›†æˆ"""
        try:
            # è¿è¡ŒéªŒè¯å¥—ä»¶
            validation_result = subprocess.run([
                sys.executable, str(self.tools_dir / "validation_suite.py"), 
                "--all", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=120)
            
            # éªŒè¯å¥—ä»¶å¯èƒ½è¿”å›éé›¶ç ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬è¾“å‡º
            if len(validation_result.stdout) < 100:
                print("âŒ éªŒè¯å¥—ä»¶è¾“å‡ºè¿‡å°‘")
                return False
            
            print("âœ… éªŒè¯å¥—ä»¶é›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ éªŒè¯å¥—ä»¶é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_ci_cd_integration(self) -> bool:
        """æµ‹è¯•CI/CDé›†æˆ"""
        try:
            # 1. è®¾ç½®CI/CDé…ç½®
            setup_result = subprocess.run([
                sys.executable, str(self.tools_dir / "ci_cd_integration.py"), 
                "--setup", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=60)
            
            if setup_result.returncode != 0:
                print(f"âŒ CI/CDè®¾ç½®å¤±è´¥: {setup_result.stderr}")
                return False
            
            # 2. è¿è¡ŒCIæµç¨‹
            ci_result = subprocess.run([
                sys.executable, str(self.tools_dir / "ci_cd_integration.py"), 
                "--run-ci", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=120)
            
            if ci_result.returncode != 0:
                print(f"âŒ CIæµç¨‹å¤±è´¥: {ci_result.stderr}")
                return False
            
            print("âœ… CI/CDé›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ CI/CDé›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_documentation_generation_integration(self) -> bool:
        """æµ‹è¯•æ–‡æ¡£ç”Ÿæˆé›†æˆ"""
        try:
            # ç”Ÿæˆæ‰€æœ‰æ–‡æ¡£
            doc_result = subprocess.run([
                sys.executable, str(self.tools_dir / "documentation_generator.py"), 
                "--all", "--root", str(self.test_env_path)
            ], capture_output=True, text=True, timeout=60)
            
            if doc_result.returncode != 0:
                print(f"âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {doc_result.stderr}")
                return False
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡æ¡£
            docs_dir = self.test_env_path / "docs"
            if not docs_dir.exists():
                print("âŒ æ–‡æ¡£ç›®å½•æœªåˆ›å»º")
                return False
            
            # æ£€æŸ¥å…³é”®æ–‡æ¡£
            key_docs = ["README.md", "guides/user_guide.md", "api/README.md"]
            for doc_path in key_docs:
                full_path = docs_dir / doc_path
                if not full_path.exists():
                    print(f"âŒ å…³é”®æ–‡æ¡£æœªç”Ÿæˆ: {doc_path}")
                    return False
            
            print("âœ… æ–‡æ¡£ç”Ÿæˆé›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡æ¡£ç”Ÿæˆé›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_integration_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œé›†æˆæµ‹è¯•")
        print("=" * 60)
        
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        if not self.setup_test_environment():
            return {"error": "æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥"}
        
        try:
            # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
            test_cases = [
                (self.test_complete_workflow, "å®Œæ•´å·¥ä½œæµæµ‹è¯•", ["simple_toc_updater", "document_automation", "comprehensive_automation"]),
                (self.test_backup_restore_workflow, "å¤‡ä»½æ¢å¤å·¥ä½œæµæµ‹è¯•", ["backup_system"]),
                (self.test_monitoring_integration, "ç›‘æ§é›†æˆæµ‹è¯•", ["monitoring_system"]),
                (self.test_template_system_integration, "æ¨¡æ¿ç³»ç»Ÿé›†æˆæµ‹è¯•", ["template_system"]),
                (self.test_performance_optimization_integration, "æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•", ["performance_optimizer"]),
                (self.test_validation_suite_integration, "éªŒè¯å¥—ä»¶é›†æˆæµ‹è¯•", ["validation_suite"]),
                (self.test_ci_cd_integration, "CI/CDé›†æˆæµ‹è¯•", ["ci_cd_integration"]),
                (self.test_documentation_generation_integration, "æ–‡æ¡£ç”Ÿæˆé›†æˆæµ‹è¯•", ["documentation_generator"])
            ]
            
            # è¿è¡Œæµ‹è¯•
            results = []
            for test_func, test_name, components in test_cases:
                print(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
                result = self.run_integration_test(test_func, test_name, components)
                results.append(result)
                
                status_icon = {
                    "passed": "âœ…",
                    "failed": "âŒ",
                    "error": "ğŸ’¥"
                }.get(result.status, "â“")
                
                print(f"   {status_icon} {result.test_name}: {result.message} ({result.duration:.2f}s)")
                print()
            
            # ç»Ÿè®¡ç»“æœ
            total_tests = len(results)
            passed_tests = sum(1 for r in results if r.status == "passed")
            failed_tests = sum(1 for r in results if r.status == "failed")
            error_tests = sum(1 for r in results if r.status == "error")
            
            total_duration = sum(r.duration for r in results)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                "test_run_time": datetime.now().isoformat(),
                "test_environment": self.test_env,
                "summary": {
                    "total_tests": total_tests,
                    "passed": passed_tests,
                    "failed": failed_tests,
                    "errors": error_tests,
                    "success_rate": (passed_tests / total_tests * 100) if total_tests > 0 else 0,
                    "total_duration": total_duration
                },
                "detailed_results": [asdict(r) for r in results],
                "component_coverage": self._analyze_component_coverage(results)
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = self.test_dir / f"integration_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # æ‰“å°æ€»ç»“
            print("=" * 60)
            print("ğŸ“Š é›†æˆæµ‹è¯•ç»“æœæ€»ç»“")
            print("=" * 60)
            print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
            print(f"é€šè¿‡: {passed_tests} âœ…")
            print(f"å¤±è´¥: {failed_tests} âŒ")
            print(f"é”™è¯¯: {error_tests} ğŸ’¥")
            print(f"æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")
            print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
            print(f"æŠ¥å‘Šæ–‡ä»¶: {report_file}")
            
            return report
            
        finally:
            # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
            self.teardown_test_environment()
    
    def _analyze_component_coverage(self, results: List[IntegrationTestResult]) -> Dict[str, Any]:
        """åˆ†æç»„ä»¶è¦†ç›–æƒ…å†µ"""
        all_components = set()
        tested_components = set()
        
        for result in results:
            for component in result.components_tested:
                all_components.add(component)
                if result.status == "passed":
                    tested_components.add(component)
        
        return {
            "total_components": len(all_components),
            "tested_components": len(tested_components),
            "coverage_percentage": (len(tested_components) / len(all_components) * 100) if all_components else 0,
            "all_components": list(all_components),
            "tested_components_list": list(tested_components),
            "untested_components": list(all_components - tested_components)
        }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é›†æˆæµ‹è¯•')
    parser.add_argument('--root', default='.', help='æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--test', help='è¿è¡ŒæŒ‡å®šæµ‹è¯•')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•')
    parser.add_argument('--report', help='ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    integration_tests = IntegrationTests(args.root)
    
    print("=" * 50)
    print("ğŸš€ é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    if args.all:
        report = integration_tests.run_all_integration_tests()
        if args.report:
            with open(args.report, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"é›†æˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")
    elif args.test:
        # è¿è¡ŒæŒ‡å®šæµ‹è¯•
        test_method = getattr(integration_tests, f"test_{args.test}", None)
        if test_method:
            if integration_tests.setup_test_environment():
                try:
                    result = integration_tests.run_integration_test(
                        test_method, args.test, [args.test]
                    )
                    print(f"æµ‹è¯•ç»“æœ: {result.status} - {result.message}")
                finally:
                    integration_tests.teardown_test_environment()
            else:
                print("âŒ æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥")
        else:
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•: {args.test}")
    else:
        print("è¯·æŒ‡å®šè¦è¿è¡Œçš„æµ‹è¯•")
        print("ä½¿ç”¨ --help æŸ¥çœ‹è¯¦ç»†å¸®åŠ©")

if __name__ == "__main__":
    main()
