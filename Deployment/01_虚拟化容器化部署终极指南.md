# è™šæ‹ŸåŒ–å®¹å™¨åŒ–éƒ¨ç½²ç»ˆææŒ‡å—

## ç›®å½•

- [1. éƒ¨ç½²æ¶æ„æ¦‚è¿°](#1-éƒ¨ç½²æ¶æ„æ¦‚è¿°)
- [2. ç¯å¢ƒå‡†å¤‡](#2-ç¯å¢ƒå‡†å¤‡)
- [3. è™šæ‹ŸåŒ–éƒ¨ç½²](#3-è™šæ‹ŸåŒ–éƒ¨ç½²)
- [4. å®¹å™¨åŒ–éƒ¨ç½²](#4-å®¹å™¨åŒ–éƒ¨ç½²)
- [5. æ··åˆéƒ¨ç½²](#5-æ··åˆéƒ¨ç½²)
- [6. ç›‘æ§ä¸è¿ç»´](#6-ç›‘æ§ä¸è¿ç»´)
- [7. æ•…éšœæ’é™¤](#7-æ•…éšœæ’é™¤)
- [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)
- [9. ç›¸å…³æ–‡æ¡£](#9-ç›¸å…³æ–‡æ¡£)

## 1. éƒ¨ç½²æ¶æ„æ¦‚è¿°

### 1.1 æ•´ä½“æ¶æ„

```yaml
éƒ¨ç½²æ¶æ„:
  åŸºç¡€è®¾æ–½å±‚:
    - ç‰©ç†æœåŠ¡å™¨
    - ç½‘ç»œè®¾å¤‡
    - å­˜å‚¨è®¾å¤‡
    - å®‰å…¨è®¾å¤‡
  
  è™šæ‹ŸåŒ–å±‚:
    - VMware vSphere
    - ESXiä¸»æœº
    - vCenter Server
    - è™šæ‹Ÿç½‘ç»œ
  
  å®¹å™¨åŒ–å±‚:
    - Docker Engine
    - Kubernetesé›†ç¾¤
    - å®¹å™¨ç¼–æ’
    - æœåŠ¡ç½‘æ ¼
  
  åº”ç”¨å±‚:
    - å¾®æœåŠ¡åº”ç”¨
    - æ•°æ®åº“æœåŠ¡
    - ç›‘æ§æœåŠ¡
    - å®‰å…¨æœåŠ¡
```

### 1.2 éƒ¨ç½²æ¨¡å¼

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    éƒ¨ç½²æ¨¡å¼é€‰æ‹©                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   çº¯è™šæ‹ŸåŒ–   â”‚  â”‚   çº¯å®¹å™¨åŒ–   â”‚  â”‚   æ··åˆéƒ¨ç½²  â”‚          â”‚
â”‚  â”‚   éƒ¨ç½²       â”‚  â”‚   éƒ¨ç½²      â”‚  â”‚             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    éƒ¨ç½²ç¯å¢ƒ                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   å¼€å‘ç¯å¢ƒ   â”‚  â”‚   æµ‹è¯•ç¯å¢ƒ  â”‚   â”‚   ç”Ÿäº§ç¯å¢ƒ  â”‚          â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. ç¯å¢ƒå‡†å¤‡

### 2.1 ç¡¬ä»¶è¦æ±‚

```yaml
ç¡¬ä»¶è¦æ±‚:
  æœ€å°é…ç½®:
    CPU: 8æ ¸å¿ƒ
    å†…å­˜: 32GB
    å­˜å‚¨: 500GB SSD
    ç½‘ç»œ: 1Gbps
  
  æ¨èé…ç½®:
    CPU: 16æ ¸å¿ƒ
    å†…å­˜: 64GB
    å­˜å‚¨: 1TB NVMe SSD
    ç½‘ç»œ: 10Gbps
  
  ç”Ÿäº§é…ç½®:
    CPU: 32æ ¸å¿ƒ
    å†…å­˜: 128GB
    å­˜å‚¨: 2TB NVMe SSD
    ç½‘ç»œ: 25Gbps
```

### 2.2 è½¯ä»¶è¦æ±‚

```bash
    # æ“ä½œç³»ç»Ÿè¦æ±‚
æ“ä½œç³»ç»Ÿ: Ubuntu 22.04 LTS / CentOS 8 / RHEL 8
å†…æ ¸ç‰ˆæœ¬: 5.4+
Dockerç‰ˆæœ¬: 24.0+
Kubernetesç‰ˆæœ¬: 1.28+
Goç‰ˆæœ¬: 1.21+
Rustç‰ˆæœ¬: 1.75+
Pythonç‰ˆæœ¬: 3.11+

    # å®‰è£…åŸºç¡€è½¯ä»¶
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git vim htop
sudo apt install -y build-essential cmake
sudo apt install -y python3-pip nodejs npm
```

### 2.3 ç½‘ç»œé…ç½®

```yaml
ç½‘ç»œé…ç½®:
  ç½‘ç»œæ‹“æ‰‘:
    ç®¡ç†ç½‘ç»œ: 192.168.1.0/24
    å­˜å‚¨ç½‘ç»œ: 192.168.2.0/24
    ä¸šåŠ¡ç½‘ç»œ: 192.168.3.0/24
    å¤–éƒ¨ç½‘ç»œ: 10.0.0.0/8
  
  ç«¯å£è¦æ±‚:
    SSH: 22
    HTTP: 80
    HTTPS: 443
    Docker API: 2376
    Kubernetes API: 6443
    etcd: 2379-2380
    kubelet: 10250
    kube-proxy: 10256
```

## 3. è™šæ‹ŸåŒ–éƒ¨ç½²

### 3.1 VMware vSphereéƒ¨ç½²

#### 3.1.1 ESXiå®‰è£…

```bash
    # ESXiå®‰è£…è„šæœ¬
#!/bin/bash

    # ä¸‹è½½ESXi ISO
wget https://downloads.vmware.com/d/info/dlg-desktop-end-user-computing/vmware_vsphere/8_0

    # åˆ›å»ºå®‰è£…è„šæœ¬
cat > esxi_install.sh << 'EOF'
    # ESXiå®‰è£…é…ç½®
install --firstdisk --overwritevmfs
rootpw VMware123!
network --bootproto=static --ip=192.168.1.100 --netmask=255.255.255.0 --gateway=192.168.1.1 --nameserver=8.8.8.8 --hostname=esxi-01
reboot
EOF

    # æ‰§è¡Œå®‰è£…
./esxi_install.sh
```

#### 3.1.2 vCenteréƒ¨ç½²

```yaml
    # vCenteréƒ¨ç½²é…ç½®
vcenter_config:
  hostname: vcenter.local
  ip_address: 192.168.1.10
  domain: local
  admin_user: administrator@vsphere.local
  admin_password: VMware123!
  
  database:
    type: embedded
    # æˆ–ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“
    # type: external
    # host: db.local
    # port: 5432
    # database: vcenter
    # username: vcenter
    # password: password123
  
  ssl:
    certificate: self-signed
    # æˆ–ä½¿ç”¨è‡ªå®šä¹‰è¯ä¹¦
    # certificate: custom
    # cert_file: /path/to/cert.pem
    # key_file: /path/to/key.pem
```

### 3.2 è™šæ‹Ÿæœºæ¨¡æ¿

```bash
    # åˆ›å»ºè™šæ‹Ÿæœºæ¨¡æ¿
#!/bin/bash

    # åˆ›å»ºCentOSæ¨¡æ¿
vmware-vdiskmanager -c -s 40GB -a lsilogic -t 0 centos-template.vmdk

    # å®‰è£…CentOS
virt-install \
  --name centos-template \
  --ram 2048 \
  --vcpus 2 \
  --disk path=centos-template.vmdk \
  --network network=default \
  --graphics none \
  --console pty,target_type=serial \
  --location /path/to/centos.iso \
  --extra-args 'console=ttyS0,115200n8 serial'

    # é…ç½®æ¨¡æ¿
ssh root@centos-template
yum update -y
yum install -y docker kubelet kubeadm kubectl
systemctl enable docker kubelet
```

## 4. å®¹å™¨åŒ–éƒ¨ç½²

### 4.1 Dockeréƒ¨ç½²

#### 4.1.1 Dockerå®‰è£…

```bash
#!/bin/bash
# Dockerå®‰è£…è„šæœ¬

# æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
if [[ "$OSTYPE" != "linux-gnu"* ]]; then
    echo "æ­¤è„šæœ¬ä»…æ”¯æŒLinuxç³»ç»Ÿ"
    exit 1
fi

# å¸è½½æ—§ç‰ˆæœ¬
sudo apt remove -y docker docker-engine docker.io containerd runc

# å®‰è£…ä¾èµ–
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release

# æ·»åŠ Dockerå®˜æ–¹GPGå¯†é’¥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# æ·»åŠ Dockerä»“åº“
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# å®‰è£…Docker
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# å¯åŠ¨DockeræœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# é…ç½®Docker
sudo usermod -aG docker $USER
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

sudo systemctl restart docker

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

#### 4.1.2 Docker Composeéƒ¨ç½²

```yaml
    # docker-compose.yml
version: '3.8'

services:
  virtualization-monitor:
    build: .
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - MONITORING_INTERVAL=30
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  container-orchestrator:
    build: .
    ports:
      - "8081:8080"
    environment:
      - GO_LOG_LEVEL=info
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config:/app/config
    restart: unless-stopped

  semantic-validator:
    build: .
    ports:
      - "8082:8080"
    environment:
      - PYTHON_DEBUG=0
      - LOG_LEVEL=info
    volumes:
      - ./config:/app/config
      - ./models:/app/models
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  prometheus-data:
  grafana-data:
```

### 4.2 Kuberneteséƒ¨ç½²

#### 4.2.1 é›†ç¾¤åˆå§‹åŒ–

```bash
    # Kubernetesé›†ç¾¤åˆå§‹åŒ–è„šæœ¬
#!/bin/bash

    # å®‰è£…kubeadm, kubelet, kubectl
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

    # åˆå§‹åŒ–ä¸»èŠ‚ç‚¹
sudo kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --apiserver-advertise-address=192.168.1.100 \
  --control-plane-endpoint=192.168.1.100:6443 \
  --upload-certs

    # é…ç½®kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

    # å®‰è£…ç½‘ç»œæ’ä»¶
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

    # å…è®¸ä¸»èŠ‚ç‚¹è°ƒåº¦Pod
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

#### 4.2.2 å·¥ä½œèŠ‚ç‚¹åŠ å…¥

```bash
    # å·¥ä½œèŠ‚ç‚¹åŠ å…¥è„šæœ¬
#!/bin/bash

    # åœ¨ä¸»èŠ‚ç‚¹è·å–åŠ å…¥å‘½ä»¤
kubeadm token create --print-join-command

    # åœ¨å·¥ä½œèŠ‚ç‚¹æ‰§è¡ŒåŠ å…¥å‘½ä»¤
sudo kubeadm join 192.168.1.100:6443 --token <token> --discovery-token-ca-cert-hash <hash>

    # éªŒè¯èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes
```

## 5. æ··åˆéƒ¨ç½²

### 5.1 è™šæ‹ŸåŒ–+å®¹å™¨åŒ–æ¶æ„

```yaml
æ··åˆéƒ¨ç½²æ¶æ„:
  è™šæ‹ŸåŒ–å±‚:
    - VMware vSphereé›†ç¾¤
    - è™šæ‹Ÿæœºèµ„æºæ± 
    - è™šæ‹Ÿç½‘ç»œ
    - å­˜å‚¨è™šæ‹ŸåŒ–
  
  å®¹å™¨åŒ–å±‚:
    - Kubernetesé›†ç¾¤
    - å®¹å™¨è¿è¡Œæ—¶
    - æœåŠ¡ç½‘æ ¼
    - å®¹å™¨å­˜å‚¨
  
  åº”ç”¨å±‚:
    - ä¼ ç»Ÿåº”ç”¨(è™šæ‹Ÿæœº)
    - å¾®æœåŠ¡åº”ç”¨(å®¹å™¨)
    - æ•°æ®åº“æœåŠ¡
    - ç›‘æ§æœåŠ¡
```

### 5.2 éƒ¨ç½²ç­–ç•¥

```bash
    # æ··åˆéƒ¨ç½²è„šæœ¬
#!/bin/bash

    # åˆ›å»ºè™šæ‹Ÿæœºç”¨äºä¼ ç»Ÿåº”ç”¨
vmware-vdiskmanager -c -s 100GB -a lsilogic -t 0 traditional-app.vmdk

    # éƒ¨ç½²ä¼ ç»Ÿåº”ç”¨åˆ°è™šæ‹Ÿæœº
virt-install \
  --name traditional-app \
  --ram 4096 \
  --vcpus 4 \
  --disk path=traditional-app.vmdk \
  --network network=default \
  --graphics none \
  --console pty,target_type=serial \
  --location /path/to/centos.iso

    # éƒ¨ç½²å¾®æœåŠ¡åˆ°Kubernetes
kubectl apply -f microservices/

    # é…ç½®æœåŠ¡å‘ç°
kubectl apply -f service-mesh/

    # é…ç½®è´Ÿè½½å‡è¡¡
kubectl apply -f ingress/
```

## 6. ç›‘æ§ä¸è¿ç»´

### 6.1 ç›‘æ§ç³»ç»Ÿéƒ¨ç½²

```yaml
    # ç›‘æ§ç³»ç»Ÿé…ç½®
monitoring_stack:
  prometheus:
    image: prom/prometheus:latest
    config: prometheus.yml
    storage: 200h
  
  grafana:
    image: grafana/grafana:latest
    dashboards: 
      - virtualization-dashboard
      - container-dashboard
      - application-dashboard
  
  alertmanager:
    image: prom/alertmanager:latest
    config: alertmanager.yml
  
  node_exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
  
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
```

### 6.2 æ—¥å¿—ç®¡ç†

```yaml
    # æ—¥å¿—ç®¡ç†ç³»ç»Ÿ
logging_stack:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
  
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
  
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
  
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
```

### 6.3 è‡ªåŠ¨åŒ–è¿ç»´

```python
    # è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬
import asyncio
import aiohttp
import json
from datetime import datetime

class AutomationOps:
    def __init__(self):
        self.k8s_api = "https://kubernetes.default.svc"
        self.vmware_api = "https://vcenter.local"
        self.monitoring_api = "http://prometheus:9090"
    
    async def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        services = [
            "virtualization-monitor",
            "container-orchestrator", 
            "semantic-validator",
            "prometheus",
            "grafana"
        ]
        
        for service in services:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"http://{service}:8080/health") as response:
                        if response.status == 200:
                            print(f"âœ… {service} å¥åº·")
                        else:
                            print(f"âŒ {service} ä¸å¥åº·")
                            await self.restart_service(service)
            except Exception as e:
                print(f"âŒ {service} æ£€æŸ¥å¤±è´¥: {e}")
                await self.restart_service(service)
    
    async def restart_service(self, service_name):
        """é‡å¯æœåŠ¡"""
        try:
            # KubernetesæœåŠ¡é‡å¯
            if service_name in ["container-orchestrator", "semantic-validator"]:
                await self.restart_k8s_deployment(service_name)
            # DockeræœåŠ¡é‡å¯
            else:
                await self.restart_docker_service(service_name)
            print(f"ğŸ”„ {service_name} å·²é‡å¯")
        except Exception as e:
            print(f"âŒ {service_name} é‡å¯å¤±è´¥: {e}")
    
    async def scale_services(self, load_metrics):
        """è‡ªåŠ¨æ‰©ç¼©å®¹"""
        for service, metrics in load_metrics.items():
            if metrics["cpu"] > 80 or metrics["memory"] > 80:
                await self.scale_up(service)
            elif metrics["cpu"] < 20 and metrics["memory"] < 20:
                await self.scale_down(service)
    
    async def backup_data(self):
        """æ•°æ®å¤‡ä»½"""
        backup_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¤‡ä»½æ•°æ®åº“
        await self.backup_database(backup_time)
        
        # å¤‡ä»½é…ç½®æ–‡ä»¶
        await self.backup_configs(backup_time)
        
        # å¤‡ä»½æ—¥å¿—
        await self.backup_logs(backup_time)
        
        print(f"âœ… å¤‡ä»½å®Œæˆ: {backup_time}")
```

## 7. æ•…éšœæ’é™¤

### 7.1 å¸¸è§é—®é¢˜è¯Šæ–­

```bash
    # æ•…éšœè¯Šæ–­è„šæœ¬
#!/bin/bash

echo "=== ç³»ç»Ÿè¯Šæ–­ ==="

    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
echo "CPUä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1

echo "å†…å­˜ä½¿ç”¨ç‡:"
free | grep Mem | awk '{printf "%.2f%%", $3/$2 * 100.0}'

echo "ç£ç›˜ä½¿ç”¨ç‡:"
df -h | grep -E '^/dev/'

    # æ£€æŸ¥ç½‘ç»œè¿æ¥
echo "ç½‘ç»œè¿æ¥çŠ¶æ€:"
netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'

    # æ£€æŸ¥DockerçŠ¶æ€
echo "DockerçŠ¶æ€:"
docker ps
docker system df

    # æ£€æŸ¥KubernetesçŠ¶æ€
echo "KubernetesçŠ¶æ€:"
kubectl get nodes
kubectl get pods --all-namespaces
kubectl get services --all-namespaces

    # æ£€æŸ¥æœåŠ¡æ—¥å¿—
echo "æœåŠ¡æ—¥å¿—:"
docker logs virtualization-monitor --tail 50
docker logs container-orchestrator --tail 50
docker logs semantic-validator --tail 50
```

### 7.2 æ€§èƒ½é—®é¢˜æ’æŸ¥

```python
    # æ€§èƒ½é—®é¢˜æ’æŸ¥å·¥å…·
import psutil
import docker
import requests
import time

class PerformanceDiagnostics:
    def __init__(self):
        self.docker_client = docker.from_env()
    
    def check_system_performance(self):
        """æ£€æŸ¥ç³»ç»Ÿæ€§èƒ½"""
        print("=== ç³»ç»Ÿæ€§èƒ½æ£€æŸ¥ ===")
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        print(f"CPUä½¿ç”¨ç‡: {cpu_percent}%")
        
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
        
        # ç£ç›˜IO
        disk_io = psutil.disk_io_counters()
        print(f"ç£ç›˜è¯»å–: {disk_io.read_bytes / 1024 / 1024:.2f} MB")
        print(f"ç£ç›˜å†™å…¥: {disk_io.write_bytes / 1024 / 1024:.2f} MB")
        
        # ç½‘ç»œIO
        network_io = psutil.net_io_counters()
        print(f"ç½‘ç»œæ¥æ”¶: {network_io.bytes_recv / 1024 / 1024:.2f} MB")
        print(f"ç½‘ç»œå‘é€: {network_io.bytes_sent / 1024 / 1024:.2f} MB")
    
    def check_container_performance(self):
        """æ£€æŸ¥å®¹å™¨æ€§èƒ½"""
        print("=== å®¹å™¨æ€§èƒ½æ£€æŸ¥ ===")
        
        containers = self.docker_client.containers.list()
        for container in containers:
            stats = container.stats(stream=False)
            
            # CPUä½¿ç”¨ç‡
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - stats['precpu_stats']['system_cpu_usage']
            cpu_percent = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage']) * 100.0
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory_usage = stats['memory_stats']['usage']
            memory_limit = stats['memory_stats']['limit']
            memory_percent = (memory_usage / memory_limit) * 100.0
            
            print(f"å®¹å™¨ {container.name}:")
            print(f"  CPUä½¿ç”¨ç‡: {cpu_percent:.2f}%")
            print(f"  å†…å­˜ä½¿ç”¨ç‡: {memory_percent:.2f}%")
    
    def check_service_response_time(self):
        """æ£€æŸ¥æœåŠ¡å“åº”æ—¶é—´"""
        print("=== æœåŠ¡å“åº”æ—¶é—´æ£€æŸ¥ ===")
        
        services = [
            "http://localhost:8080/health",
            "http://localhost:8081/health", 
            "http://localhost:8082/health",
            "http://localhost:9090/-/healthy",
            "http://localhost:3000/api/health"
        ]
        
        for service_url in services:
            try:
                start_time = time.time()
                response = requests.get(service_url, timeout=5)
                response_time = time.time() - start_time
                
                if response.status_code == 200:
                    print(f"âœ… {service_url}: {response_time:.3f}s")
                else:
                    print(f"âŒ {service_url}: HTTP {response.status_code}")
            except Exception as e:
                print(f"âŒ {service_url}: {e}")
```

## 8. æœ€ä½³å®è·µ

### 8.1 éƒ¨ç½²æœ€ä½³å®è·µ

```yaml
éƒ¨ç½²æœ€ä½³å®è·µ:
  ç¯å¢ƒéš”ç¦»:
    å¼€å‘ç¯å¢ƒ: å•èŠ‚ç‚¹éƒ¨ç½²
    æµ‹è¯•ç¯å¢ƒ: å°è§„æ¨¡é›†ç¾¤
    ç”Ÿäº§ç¯å¢ƒ: é«˜å¯ç”¨é›†ç¾¤
  
  èµ„æºè§„åˆ’:
    CPU: é¢„ç•™20%èµ„æº
    å†…å­˜: é¢„ç•™30%èµ„æº
    å­˜å‚¨: é¢„ç•™50%ç©ºé—´
    ç½‘ç»œ: é¢„ç•™å¸¦å®½
  
  å®‰å…¨é…ç½®:
    å¯ç”¨é˜²ç«å¢™: é™åˆ¶ç«¯å£è®¿é—®
    ä½¿ç”¨HTTPS: åŠ å¯†é€šä¿¡
    å®šæœŸæ›´æ–°: å®‰å…¨è¡¥ä¸
    è®¿é—®æ§åˆ¶: æœ€å°æƒé™
  
  ç›‘æ§å‘Šè­¦:
    èµ„æºç›‘æ§: CPU/å†…å­˜/ç£ç›˜
    åº”ç”¨ç›‘æ§: å“åº”æ—¶é—´/é”™è¯¯ç‡
    æ—¥å¿—ç›‘æ§: å¼‚å¸¸æ—¥å¿—
    å‘Šè­¦é€šçŸ¥: åŠæ—¶é€šçŸ¥
```

### 8.2 è¿ç»´æœ€ä½³å®è·µ

```bash
    # è¿ç»´æœ€ä½³å®è·µè„šæœ¬
#!/bin/bash

    # å®šæœŸç»´æŠ¤ä»»åŠ¡
maintenance_tasks() {
    echo "=== å®šæœŸç»´æŠ¤ä»»åŠ¡ ==="
    
    # æ¸…ç†Dockeré•œåƒ
    docker system prune -f
    
    # æ¸…ç†Kubernetesèµ„æº
    kubectl delete pods --field-selector=status.phase=Succeeded
    kubectl delete pods --field-selector=status.phase=Failed
    
    # æ¸…ç†æ—¥å¿—æ–‡ä»¶
    find /var/log -name "*.log" -mtime +30 -delete
    
    # æ›´æ–°ç³»ç»ŸåŒ…
    apt update && apt upgrade -y
    
    # é‡å¯æœåŠ¡
    systemctl restart docker
    systemctl restart kubelet
}

    # å¤‡ä»½è„šæœ¬
backup_script() {
    echo "=== æ•°æ®å¤‡ä»½ ==="
    
    backup_dir="/backup/$(date +%Y%m%d)"
    mkdir -p $backup_dir
    
    # å¤‡ä»½é…ç½®æ–‡ä»¶
    cp -r /etc/docker $backup_dir/
    cp -r /etc/kubernetes $backup_dir/
    
    # å¤‡ä»½æ•°æ®
    docker run --rm -v /var/lib/docker:/data -v $backup_dir:/backup alpine tar czf /backup/docker-data.tar.gz /data
    
    # å¤‡ä»½æ•°æ®åº“
    kubectl exec -n default postgres-0 -- pg_dump -U postgres postgres > $backup_dir/database.sql
    
    echo "å¤‡ä»½å®Œæˆ: $backup_dir"
}

    # ç›‘æ§è„šæœ¬
monitoring_script() {
    echo "=== ç³»ç»Ÿç›‘æ§ ==="
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    systemctl is-active docker
    systemctl is-active kubelet
    
    # æ£€æŸ¥èµ„æºä½¿ç”¨
    df -h
    free -h
    top -bn1 | head -5
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'
}

    # æ‰§è¡Œç»´æŠ¤ä»»åŠ¡
case "$1" in
    "maintenance")
        maintenance_tasks
        ;;
    "backup")
        backup_script
        ;;
    "monitor")
        monitoring_script
        ;;
    *)
        echo "ç”¨æ³•: $0 {maintenance|backup|monitor}"
        exit 1
        ;;
esac
```

### 8.3 æ•…éšœæ¢å¤

```yaml
æ•…éšœæ¢å¤ç­–ç•¥:
  æœåŠ¡æ•…éšœ:
    è‡ªåŠ¨é‡å¯: é…ç½®é‡å¯ç­–ç•¥
    å¥åº·æ£€æŸ¥: å®šæœŸå¥åº·æ£€æŸ¥
    æ•…éšœè½¬ç§»: è‡ªåŠ¨æ•…éšœè½¬ç§»
    è´Ÿè½½å‡è¡¡: åˆ†æ•£è´Ÿè½½
  
  æ•°æ®æ•…éšœ:
    æ•°æ®å¤‡ä»½: å®šæœŸå¤‡ä»½
    æ•°æ®æ¢å¤: å¿«é€Ÿæ¢å¤
    æ•°æ®åŒæ­¥: å®æ—¶åŒæ­¥
    æ•°æ®éªŒè¯: å®Œæ•´æ€§æ£€æŸ¥
  
  ç½‘ç»œæ•…éšœ:
    ç½‘ç»œå†—ä½™: å¤šè·¯å¾„ç½‘ç»œ
    æ•…éšœæ£€æµ‹: ç½‘ç»œç›‘æ§
    è‡ªåŠ¨åˆ‡æ¢: ç½‘ç»œåˆ‡æ¢
    æ•…éšœéš”ç¦»: ç½‘ç»œéš”ç¦»
  
  ç¡¬ä»¶æ•…éšœ:
    ç¡¬ä»¶å†—ä½™: å†—ä½™ç¡¬ä»¶
    æ•…éšœæ£€æµ‹: ç¡¬ä»¶ç›‘æ§
    è‡ªåŠ¨åˆ‡æ¢: ç¡¬ä»¶åˆ‡æ¢
    æ•…éšœéš”ç¦»: ç¡¬ä»¶éš”ç¦»
```

## 9. ç›¸å…³æ–‡æ¡£

### æ ¸å¿ƒæŠ€æœ¯æ–‡æ¡£

- [Dockeræ¶æ„åŸç†](../Container/01_DockeræŠ€æœ¯è¯¦è§£/01_Dockeræ¶æ„åŸç†.md) - å®¹å™¨æŠ€æœ¯åŸºç¡€
- [Kubernetesæ¶æ„åŸç†](../Container/03_KubernetesæŠ€æœ¯è¯¦è§£/01_Kubernetesæ¶æ„åŸç†.md) - å®¹å™¨ç¼–æ’åŸºç¡€
- [vSphereæ¶æ„æ¦‚è¿°](../vShpere_VMware/01_vSphereåŸºç¡€æ¶æ„/01_vSphereæ¶æ„æ¦‚è¿°.md) - è™šæ‹ŸåŒ–åŸºç¡€
- [ESXiå®‰è£…é…ç½®](../vShpere_VMware/02_ESXiæŠ€æœ¯è¯¦è§£/02_ESXiå®‰è£…é…ç½®.md) - è™šæ‹ŸåŒ–å¹³å°å®‰è£…

### æŠ€æœ¯å®æ–½æ–‡æ¡£

- [æŠ€æœ¯å®æ–½æŒ‡å—ä¸æœ€ä½³å®è·µ](../Analysis/02_æŠ€æœ¯å®æ–½æŒ‡å—ä¸æœ€ä½³å®è·µ.md) - å®Œæ•´å®æ–½æŒ‡å¯¼
- [æ€§èƒ½åˆ†æä¸ä¼˜åŒ–ç»¼åˆæŒ‡å—](../Analysis/04_æ€§èƒ½åˆ†æä¸ä¼˜åŒ–ç»¼åˆæŒ‡å—.md) - æ€§èƒ½è°ƒä¼˜æŒ‡å—
- [æŠ€æœ¯æ ‡å‡†åˆè§„æ€§ä¸å¯¹æ ‡åˆ†æ](../Analysis/03_æŠ€æœ¯æ ‡å‡†åˆè§„æ€§ä¸å¯¹æ ‡åˆ†æ.md) - æ ‡å‡†åˆè§„æ€§

### å®‰å…¨ä¸è¿ç»´æ–‡æ¡£

- [å®‰å…¨æ¶æ„æŒ‡å—](../Security/01_è™šæ‹ŸåŒ–å®¹å™¨åŒ–å®‰å…¨æ¶æ„ç»ˆææŒ‡å—.md) - å®‰å…¨è®¾è®¡æŒ‡å¯¼
- [è¯­ä¹‰æ¨¡å‹éªŒè¯å·¥å…·](../Semantic/04_è¯­ä¹‰æ¨¡å‹éªŒè¯å·¥å…·ä¸ä»£ç å®ç°.md) - ç³»ç»ŸéªŒè¯å·¥å…·
- [é¡¹ç›®å¯¼èˆªä¸ä½¿ç”¨æŒ‡å—](../é¡¹ç›®å¯¼èˆªä¸ä½¿ç”¨æŒ‡å—.md) - å®Œæ•´å­¦ä¹ è·¯å¾„

### å­¦ä¹ èµ„æº

- [Dockerå®¹å™¨ç®¡ç†](../Container/01_DockeræŠ€æœ¯è¯¦è§£/02_Dockerå®¹å™¨ç®¡ç†.md) - å®¹å™¨è¿ç»´å®è·µ
- [vCenterç®¡ç†æŠ€æœ¯](../vShpere_VMware/03_vCenter ServeræŠ€æœ¯/01_vCenteræ¶æ„åŸç†.md) - è™šæ‹ŸåŒ–ç®¡ç†
- [ç½‘ç»œè™šæ‹ŸåŒ–æŠ€æœ¯](../vShpere_VMware/06_ç½‘ç»œè™šæ‹ŸåŒ–æŠ€æœ¯/01_NSXæ¶æ„åŸç†.md) - ç½‘ç»œæŠ€æœ¯
- [å­˜å‚¨è™šæ‹ŸåŒ–æŠ€æœ¯](../vShpere_VMware/05_å­˜å‚¨è™šæ‹ŸåŒ–æŠ€æœ¯/01_vSANæ¶æ„åŸç†.md) - å­˜å‚¨æŠ€æœ¯

---

*æœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„è™šæ‹ŸåŒ–å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç¯å¢ƒå‡†å¤‡ã€éƒ¨ç½²å®æ–½ã€ç›‘æ§è¿ç»´å’Œæ•…éšœæ’é™¤ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šå¯é è¿è¡Œã€‚*
